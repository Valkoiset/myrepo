{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.preprocessing import Imputer # this one is old, now use SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# from sklearn.feature_selection import RFE\n",
    "# from sklearn.linear_model import BayesianRidge\n",
    "# import statsmodels.api as sm\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig = pd.read_csv('rain.csv', index_col=0)\n",
    "df_miss = pd.read_csv('RAIN_MISS.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop additional columns indicators created in SAS\n",
    "df_miss = df_miss.drop(['id', 'Missing1', 'Missing2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# number of columns with missing values\n",
    "print(df_orig.isnull().any().sum())\n",
    "print(df_miss.isnull().any().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in columns\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Humidity9am    22785\n",
       "Humidity3pm    22785\n",
       "Pressure9am    34035\n",
       "Pressure3pm    34035\n",
       "dtype: int64"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Number of missing values in columns\\n')\n",
    "df_miss[['Humidity9am', 'Humidity3pm', 'Pressure9am', 'Pressure3pm']].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dummy variables\n",
    "df_dummies_orig = pd.get_dummies(df_orig)\n",
    "df_dummies_miss = pd.get_dummies(df_miss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividing into features and dependent variable\n",
    "X_orig = df_dummies_orig.drop('RainTomorrow', axis=1)\n",
    "y_orig = df_dummies_orig['RainTomorrow']\n",
    "\n",
    "X_miss = df_dummies_miss.drop('RainTomorrow', axis=1)\n",
    "y_miss = df_dummies_miss['RainTomorrow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test splits\n",
    "X_train_orig, X_test_orig, y_train_orig, y_test_orig = train_test_split(X_orig, y_orig, test_size=0.3, random_state=42)\n",
    "X_train_miss, X_test_miss, y_train_miss, y_test_miss = train_test_split(X_miss, y_miss, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic for original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_orig = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_orig.fit(X_train_orig, y_train_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_orig = logreg_orig.predict(X_test_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8521459354153138"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_orig_score = logreg_orig.score(X_test_orig, y_test_orig)\n",
    "logreg_orig_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic for imputed dataset\n",
    "- imputing with mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "logreg_miss_mean = LogisticRegression()\n",
    "steps_mean = [('imputation', imp_mean), ('logistic_regression', logreg_miss_mean)]\n",
    "pipeline_mean = Pipeline(steps_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('imputation',\n",
       "                 SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
       "                               missing_values=nan, strategy='mean',\n",
       "                               verbose=0)),\n",
       "                ('logistic_regression',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='warn', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_mean.fit(X_train_miss, y_train_miss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_miss_mean = pipeline_mean.predict(X_test_miss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.840722592833107"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_miss_mean_score = pipeline_mean.score(X_test_miss, y_test_miss)\n",
    "logreg_miss_mean_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Multivariate feature imputation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_multivar = IterativeImputer(max_iter=25, random_state=0)\n",
    "logreg_miss_multivar = LogisticRegression()\n",
    "steps_multivar = [('imputation', imp_multivar), ('logistic_regression', logreg_miss_multivar)]\n",
    "pipeline_multivar = Pipeline(steps_multivar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('imputation',\n",
       "                 IterativeImputer(add_indicator=False, estimator=None,\n",
       "                                  imputation_order='ascending',\n",
       "                                  initial_strategy='mean', max_iter=25,\n",
       "                                  max_value=None, min_value=None,\n",
       "                                  missing_values=nan, n_nearest_features=None,\n",
       "                                  random_state=0, sample_posterior=False,\n",
       "                                  tol=0.001, verbose=0)),\n",
       "                ('logistic_regression',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='warn', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_multivar.fit(X_train_miss, y_train_miss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_miss_multivar = pipeline_mean.predict(X_test_miss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8468917881811205"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_miss_multivar_score = pipeline_multivar.score(X_test_miss, y_test_miss)\n",
    "logreg_miss_multivar_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg score of \n",
      " original dataset: 0.8521459354153138 \n",
      " imputed with mean: 0.840722592833107 \n",
      " multivariate feature imputation: 0.8468917881811205\n"
     ]
    }
   ],
   "source": [
    "print('logreg score of \\n original dataset:', logreg_orig_score, '\\n', 'imputed with mean:', logreg_miss_mean_score, '\\n', 'multivariate feature imputation:', logreg_miss_multivar_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "# print(classification_report(y_test_miss, y_pred_miss_multivar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
