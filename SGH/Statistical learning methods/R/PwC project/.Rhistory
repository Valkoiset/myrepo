py_config()
use_python(python = Sys.which("python3"), required = TRUE)
tensorflow::install_tensorflow()
py_config()
Sys.setenv(RETICULATE_PYTHON = "/Macintosh HD/Applications/Python 3.7.2
py_config()
reticulate::py_discover_config("keras")
py_config()
use_python(python = "/usr/bin/python3.7.2", required = TRUE)
library(reticulate)
use_python(python = Sys.which("python3"), required = TRUE)
py_config()
# Sys.setenv(RETICULATE_PYTHON = "/Macintosh HD/Applications/Python 3.7.2")
Sys.setenv(RETICULATE_PYTHON = "/anaconda3/lib/python3.7.2")
py_config()
Sys.setenv(RETICULATE_PYTHON = "/Macintosh HD/Applications/Python 3.7.2
py_config()
use_python(python = Sys.which("python3"), required = TRUE)
py_config()
Sys.setenv(RETICULATE_PYTHON = "/usr/local/bin/python3")
use_python(python = Sys.which("python3"), required = TRUE)
py_config()
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(keras)
mnist <- dataset_mnist()
library(keras)
mnist <- dataset_mnist()
library(keras)
library(keras)
mnist <- dataset_mnist()
library(keras)
mnist <- dataset_mnist()
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(keras)
mnist <- dataset_mnist()
use_python(python = Sys.which("python3"), required = TRUE)
py_config()
# Sys.setenv(RETICULATE_PYTHON = "/Macintosh HD/Applications/Python 3.7.2")
# Sys.setenv(RETICULATE_PYTHON = "/anaconda3/lib/python3.7.2")
Sys.setenv(RETICULATE_PYTHON = "/usr/local/bin/python3")
use_python(python = Sys.which("python3"), required = TRUE)
py_config()
py_config()
library(keras)
mnist <- dataset_mnist()
library(reticulate)
py_config()
# -------------------------------------------------------------------
library(reticulate)
# Sys.setenv(RETICULATE_PYTHON = "/Macintosh HD/Applications/Python 3.7.2")
# Sys.setenv(RETICULATE_PYTHON = "/anaconda3/lib/python3.7.2")
Sys.setenv(RETICULATE_PYTHON = "/usr/local/bin/python3")
use_python(python = Sys.which("python3"), required = TRUE)
py_config()
library(keras)
mnist <- dataset_mnist()
# Sys.setenv(RETICULATE_PYTHON = "/Macintosh HD/Applications/Python 3.7.2")
# Sys.setenv(RETICULATE_PYTHON = "/anaconda3/lib/python3.7.2")
Sys.setenv(RETICULATE_PYTHON = "/usr/local/bin/python3")
use_python(python = Sys.which("python3"), required = TRUE)
py_config()
# Sys.setenv(RETICULATE_PYTHON = "/Macintosh HD/Applications/Python 3.7.2")
# Sys.setenv(RETICULATE_PYTHON = "/anaconda3/lib/python3.7.2")
Sys.setenv(RETICULATE_PYTHON = "/usr/local/bin/python3")
py_config()
# -------------------------------------------------------------------
library(reticulate)
# Sys.setenv(RETICULATE_PYTHON = "/Macintosh HD/Applications/Python 3.7.2")
# Sys.setenv(RETICULATE_PYTHON = "/anaconda3/lib/python3.7.2")
Sys.setenv(RETICULATE_PYTHON = "/usr/local/bin/python3")
use_python(python = Sys.which("python3"), required = TRUE)
py_config()
library(keras)
mnist <- dataset_mnist()
# -------------------------------------------------------------------
library(reticulate)
# Sys.setenv(RETICULATE_PYTHON = "/Macintosh HD/Applications/Python 3.7.2")
# Sys.setenv(RETICULATE_PYTHON = "/anaconda3/lib/python3.7.2")
Sys.setenv(RETICULATE_PYTHON = "/usr/local/bin/python3")
use_python(python = Sys.which("python3"), required = TRUE)
py_config()
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(keras)
mnist <- dataset_mnist()
# Sys.setenv(RETICULATE_PYTHON = "/Macintosh HD/Applications/Python 3.7.2")
# Sys.setenv(RETICULATE_PYTHON = "/anaconda3/lib/python3.7.2")
Sys.setenv(RETICULATE_PYTHON = "/usr/local/bin/python3")
use_python(python = Sys.which("python3"), required = TRUE)
py_config()
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(keras)
mnist <- dataset_mnist()
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(keras)
mnist <- dataset_mnist()
# Sys.setenv(RETICULATE_PYTHON = "/Macintosh HD/Applications/Python 3.7.2")
# Sys.setenv(RETICULATE_PYTHON = "/anaconda3/lib/python3.7.2")
Sys.setenv(RETICULATE_PYTHON = "/usr/local/bin/python3")
py_config()
library(keras)
mnist <- dataset_mnist()
Sys.setenv(RETICULATE_PYTHON = "/Macintosh HD/Applications/Python 3.7.2
py_config()
use_python(python = Sys.which("python3"), required = TRUE)
# !!!! -------------------------------------------------------------------
library(reticulate)
# Sys.setenv(RETICULATE_PYTHON = "/Macintosh HD/Applications/Python 3.7.2")
# Sys.setenv(RETICULATE_PYTHON = "/anaconda3/lib/python3.7.2")
Sys.setenv(RETICULATE_PYTHON = "/usr/local/bin/python3")
use_python(python = Sys.which("python3"), required = TRUE)
py_config()
reticulate::py_discover_config("keras")
devtools::install_github("rstudio/keras")
reticulate::py_discover_config("keras")
reticulate::py_discover_config("tensorflow")
library(keras)
mnist <- dataset_mnist()
use_python(python = Sys.which("python3"), required = TRUE)
py_config()
library(keras)
install_tensorflow()
install_tensorflow()
devtools::install_github("rstudio/tensorflow")
# Read in MNIST data
mnist <- dataset_mnist()
install_tensorflow()
library(tensorflow)
install_tensorflow()
library(keras)
library(tensorflow)
sess = tf$Session()
hello <- tf$constant('Hello, TensorFlow!')
sess$run(hello)
# Read in MNIST data
mnist <- dataset_mnist()
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(keras)
mnist <- dataset_mnist()
train_images <- mnist$train$x
train_labels <- mnist$train$y
test_images <- mnist$test$x
test_labels <- mnist$test$y
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(keras)
mnist <- dataset_mnist()
train_images <- mnist$train$x
train_labels <- mnist$train$y
test_images <- mnist$test$x
test_labels <- mnist$test$y
View(mnist)
str(train_images)
str(train_labels)
str(test_images)
str(test_labels)
network <- keras_model_sequential() %>%
layer_dense(units = 512, activation = "relu", input_shape = c(28 * 28)) %>%
layer_dense(units = 10, activation = "softmax")
network %>% compile(
optimizer = "rmsprop",
loss = "categorical_crossentropy",
metrics = c("accuracy")
)
train_images <- array_reshape(train_images, c(60000, 28 * 28))
train_images <- train_images / 255
test_images <- array_reshape(test_images, c(10000, 28 * 28))
test_images <- test_images / 255
train_labels <- to_categorical(train_labels)
test_labels <- to_categorical(test_labels)
View(train_labels)
network %>% fit(train_images, train_labels, epochs = 5, batch_size = 128)
metrics <- network %>% evaluate(test_images, test_labels, verbose = 0)
metrics
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(keras)
mnist <- dataset_mnist()
train_images <- mnist$train$x
train_labels <- mnist$train$y
test_images <- mnist$test$x
test_labels <- mnist$test$y
system.time(m <- matrix(rnorm(10000^2), ncol=10000))
m
system.time(m[lower.tri(m)] <- 0)
system.time(sum(m))
View(m)
rm(list=ls())
require(xgboost)
data(agaricus.train, package='xgboost')
data(agaricus.test, package='xgboost')
train <- agaricus.train
test <- agaricus.test
str(train)
dim(train$data)
dim(test$data)
library(BCA)
library(relimp)
library(car)
library(RcmdrMisc)
library(foreign)
library(corrplot)
library(dplyr)
# Loading data
Wesbrook <- read.dbf("~/Desktop/SGH/2 semester/Big data/labs/4/Wesbrook.dbf", as.is=FALSE)
variable.summary(Wesbrook)
# Removing some variables
Wesbrook <- within(Wesbrook, {
ID <- NULL
INDUPDT <- NULL
BIGBLOCK <- NULL # 1 level factor variable
MARITAL <- NULL
MAJOR1 <- NULL
})
# Creating numerical variable from factor variable WESBROOK
Wesbrook <- within(Wesbrook, {
WESBROOK <- Recode(WESBROOK, '"Y"=1; "N"=0', as.factor=FALSE)
})
# Creating estimation and validation subsets
set.seed(323)
Wesbrook$Sample <- create.samples(Wesbrook, est = 0.7, val = 0.3)
# Excluding all NA from Wesbrook
Wesbrook <- na.exclude(Wesbrook)
# Checking if there are still some NA values
any(is.na(Wesbrook))
# Generalized linear model after excluding some variables
GLM <- glm(WESBROOK ~ . , family=binomial(logit), data=Wesbrook)
summary(GLM)
variable.summary(GLM)
variable.summary(Wesbrook)
summary(GLM)
Wesbrook$DEPT1 <- as.numeric(Wesbrook$DEPT1)
Wesbrook$FACULTY1 <- as.numeric(Wesbrook$FACULTY1)
# Generalized linear model after excluding some variables
GLM <- glm(WESBROOK ~ . , family=binomial(logit), data=Wesbrook)
summary(GLM)
variable.summary(Wesbrook)
# R2 McFadden value
1 - (GLM$deviance/GLM$null.deviance) # 0.7724513
# Selecting 70% of observations for training model
Wesbrook.est <- Wesbrook %>% filter(Sample == "Estimation")
# Selecting only statistically significant variables and dependent one
Wesbrook.est <- Wesbrook.est[, c("TOTLGIVE", "PARENT", "CHILD", "OTHERACT", "WESBROOK")]
rm(list=ls())                      # clean environment
if(!is.null(dev.list())) dev.off() # clean all plots
cat("\014")                        # clean console
# Loading data
Wesbrook <- read.dbf("~/Desktop/SGH/2 semester/Big data/labs/4/Wesbrook.dbf", as.is=FALSE)
variable.summary(Wesbrook)
# Removing some variables
Wesbrook <- within(Wesbrook, {
ID <- NULL
INDUPDT <- NULL
BIGBLOCK <- NULL # 1 level factor variable
MARITAL <- NULL
MAJOR1 <- NULL
})
# Creating numerical variable from factor variable WESBROOK
Wesbrook <- within(Wesbrook, {
WESBROOK <- Recode(WESBROOK, '"Y"=1; "N"=0', as.factor=FALSE)
})
# Creating estimation and validation subsets
set.seed(323)
Wesbrook$Sample <- create.samples(Wesbrook, est = 0.7, val = 0.3)
# Excluding all NA from Wesbrook
Wesbrook <- na.exclude(Wesbrook)
# Checking if there are still some NA values
any(is.na(Wesbrook))
# Generalized linear model after excluding some variables
GLM <- glm(WESBROOK ~ . , family=binomial(logit), data=Wesbrook)
summary(GLM)
# R2 McFadden value
1 - (GLM$deviance/GLM$null.deviance) # 0.7724513
# Selecting 70% of observations for training model
Wesbrook.est <- Wesbrook %>% filter(Sample == "Estimation")
# Selecting only statistically significant variables and dependent one
Wesbrook.est <- Wesbrook.est[, c("TOTLGIVE", "PARENT", "CHILD", "OTHERACT", "WESBROOK")]
# Generalized linear model after excluding all insignificant variables
GLM2 <- glm(WESBROOK ~ . , family=binomial(logit), data = Wesbrook.est)
summary(GLM2)
1 - (GLM2$deviance/GLM2$null.deviance) # 0.720267
# Creating Log columns
Wesbrook.est$LogTOTLGIVE <- with(Wesbrook.est, log(TOTLGIVE))
# Model after transforming numerical columns to logs
GLM3<- glm(WESBROOK ~ LogTOTLGIVE + PARENT + CHILD + OTHERACT, family = binomial(logit), data = Wesbrook.est)
summary(GLM3)
1 - (GLM3$deviance/GLM3$null.deviance) # 0.7502665
library(BCA)
library(relimp)
library(car)
library(RcmdrMisc)
# Loading CCS dataset from BCA package
data(CCS, package="BCA")
# Creating validation and estimation subsets
set.seed(321)
CCS$Sample <- create.samples(CCS, est = 0.7, val = 0.3)
View(CCS)
# Creating numerical variable from factor variable MonthsGive
CCS <- within(CCS, {
MonthGive.Num <- Recode(MonthGive, '"Yes"=1; "No"=0', as.factor=FALSE) # Recode changes values from yes/no to 1/0
})
# Variables distribution chart
scatterplot(MonthGive.Num~AveDonAmt, reg.line=lm, smooth=TRUE,
id.n = 2, boxplots='xy', span=0.5, data=CCS)
# Means chart for Region variable
with(CCS, plotMeans(MonthGive.Num, Region, error.bars="none")) # plotmeans plots mean values of variables
# Reorganizing levels of Region factor variable
CCS$NRegion <- relabel.factor(CCS$Region, new.labels=c('NR1','NR1','NR1',
'NR2','NR2','NR2'))
with(CCS, plotMeans(MonthGive.Num, NRegion))
# Generalized linear model
GLM.2 <- glm(MonthGive ~ Age20t29 +Age20t39 + Age60pls + Age70pls + Age80pls +
AveDonAmt + AveIncEA + DonPerYear + EngPrmLang + FinUnivP + LastDonAmt +
NewDonor+NRegion, family=binomial(logit), data=CCS)
variable.summary(GLM.2)
variable.summary(CCS)
library(BCA)
library(relimp)
library(car)
library(RcmdrMisc)
library(foreign)
library(corrplot)
library(dplyr)
rm(list=ls())                      # clean environment
if(!is.null(dev.list())) dev.off() # clean all plots
cat("\014")                        # clean console
# Loading data
Wesbrook <- read.dbf("~/Desktop/SGH/2 semester/Big data/labs/4/Wesbrook.dbf", as.is=FALSE)
variable.summary(Wesbrook)
# Removing some variables
Wesbrook <- within(Wesbrook, {
ID <- NULL
INDUPDT <- NULL
BIGBLOCK <- NULL # 1 level factor variable
MARITAL <- NULL
MAJOR1 <- NULL
})
# Removing some variables
Wesbrook <- within(Wesbrook, {
ID <- NULL
INDUPDT <- NULL
BIGBLOCK <- NULL # 1 level factor variable
MARITAL <- NULL
MAJOR1 <- NULL
})
variable.summary(Wesbrook)
PARENT <- Recode(PARENT, '"Y"=1; "N"=0', as.factor=FALSE)
View(Wesbrook)
# Creating numerical variable from factor variable WESBROOK
Wesbrook <- within(Wesbrook, {
WESBROOK <- Recode(WESBROOK, '"Y"=1; "N"=0', as.factor=FALSE)
PARENT <- Recode(PARENT, '"Y"=1; "N"=0', as.factor=FALSE)
})
OTHERACT <- Recode(OTHERACT, '"Y"=1; "N"=0', as.factor=FALSE)
# Creating numerical variable from factor variable WESBROOK
Wesbrook <- within(Wesbrook, {
WESBROOK <- Recode(WESBROOK, '"Y"=1; "N"=0', as.factor=FALSE)
PARENT <- Recode(PARENT, '"Y"=1; "N"=0', as.factor=FALSE)
CHILD <- Recode(CHILD, '"Y"=1; "N"=0', as.factor=FALSE)
SPOUSE <- Recode(SPOUSE, '"Y"=1; "N"=0', as.factor=FALSE)
SEX <- Recode(SEX, '"Y"=1; "N"=0', as.factor=FALSE)
FACSTAFF <- Recode(FACSTAFF, '"Y"=1; "N"=0', as.factor=FALSE)
ATHLTCS <- Recode(ATHLTCS, '"Y"=1; "N"=0', as.factor=FALSE)
OTHERACT <- Recode(OTHERACT, '"Y"=1; "N"=0', as.factor=FALSE)
})
# Creating estimation and validation subsets
set.seed(323)
Wesbrook$Sample <- create.samples(Wesbrook, est = 0.7, val = 0.3)
# Excluding all NA from Wesbrook
Wesbrook <- na.exclude(Wesbrook)
# Checking if there are still some NA values
any(is.na(Wesbrook))
# Generalized linear model after excluding some variables
GLM <- glm(WESBROOK ~ . , family=binomial(logit), data=Wesbrook)
summary(GLM)
# R2 McFadden value
1 - (GLM$deviance/GLM$null.deviance) # 0.7724513
rm(list=ls())                      # clean environment
if(!is.null(dev.list())) dev.off() # clean all plots
cat("\014")                        # clean console
# Loading data
Wesbrook <- read.dbf("~/Desktop/SGH/2 semester/Big data/labs/4/Wesbrook.dbf", as.is=FALSE)
# Removing some variables
Wesbrook <- within(Wesbrook, {
ID <- NULL
INDUPDT <- NULL
BIGBLOCK <- NULL # 1 level factor variable
MARITAL <- NULL
MAJOR1 <- NULL
})
# Creating numerical variable from factor variable WESBROOK
Wesbrook <- within(Wesbrook, {
WESBROOK <- Recode(WESBROOK, '"Y"=1; "N"=0', as.factor=FALSE)
# PARENT <- Recode(PARENT, '"Y"=1; "N"=0', as.factor=FALSE)
# CHILD <- Recode(CHILD, '"Y"=1; "N"=0', as.factor=FALSE)
# SPOUSE <- Recode(SPOUSE, '"Y"=1; "N"=0', as.factor=FALSE)
# SEX <- Recode(SEX, '"Y"=1; "N"=0', as.factor=FALSE)
# FACSTAFF <- Recode(FACSTAFF, '"Y"=1; "N"=0', as.factor=FALSE)
# ATHLTCS <- Recode(ATHLTCS, '"Y"=1; "N"=0', as.factor=FALSE)
# OTHERACT <- Recode(OTHERACT, '"Y"=1; "N"=0', as.factor=FALSE)
})
rm(list=ls())                      # clean environment
if(!is.null(dev.list())) dev.off() # clean all plots
cat("\014")                        # clean console
# Loading data
Wesbrook <- read.dbf("~/Desktop/SGH/2 semester/Big data/labs/4/Wesbrook.dbf", as.is=FALSE)
# Removing some variables
Wesbrook <- within(Wesbrook, {
ID <- NULL
INDUPDT <- NULL
BIGBLOCK <- NULL # 1 level factor variable
MARITAL <- NULL
MAJOR1 <- NULL
})
# Creating estimation and validation subsets
set.seed(323)
Wesbrook$Sample <- create.samples(Wesbrook, est = 0.7, val = 0.3)
# Excluding all NA from Wesbrook
Wesbrook <- na.exclude(Wesbrook)
# Checking if there are still some NA values
any(is.na(Wesbrook))
# Generalized linear model after excluding some variables
GLM <- glm(WESBROOK ~ . , family=binomial(logit), data=Wesbrook)
summary(GLM)
# R2 McFadden value
1 - (GLM$deviance/GLM$null.deviance) # 0.7724513
rm(list=ls())                      # clean environment
if(!is.null(dev.list())) dev.off() # clean all plots
cat("\014")                        # clean console
# Loading data
Wesbrook <- read.dbf("~/Desktop/SGH/2 semester/Big data/labs/4/Wesbrook.dbf", as.is=FALSE)
# Removing some variables
Wesbrook <- within(Wesbrook, {
ID <- NULL
INDUPDT <- NULL
BIGBLOCK <- NULL # 1 level factor variable
MARITAL <- NULL
MAJOR1 <- NULL
})
# Creating numerical variable from factor variable WESBROOK
Wesbrook <- within(Wesbrook, {
WESBROOK <- Recode(WESBROOK, '"Y"=1; "N"=0', as.factor = F)
})
# Creating estimation and validation subsets
set.seed(323)
Wesbrook$Sample <- create.samples(Wesbrook, est = 0.7, val = 0.3)
# Excluding all NA from Wesbrook
Wesbrook <- na.exclude(Wesbrook)
# Checking if there are still some NA values
any(is.na(Wesbrook))
# Generalized linear model after excluding some variables
GLM <- glm(WESBROOK ~ . , family=binomial(logit), data=Wesbrook)
summary(GLM)
# R2 McFadden value
1 - (GLM$deviance/GLM$null.deviance) # 0.7724513
# Selecting 70% of observations for training model
Wesbrook.est <- Wesbrook %>% filter(Sample == "Estimation")
# Selecting only statistically significant variables and dependent one
Wesbrook.est <- Wesbrook.est[, c("TOTLGIVE", "PARENT", "CHILD", "OTHERACT", "WESBROOK")]
# Generalized linear model after excluding all insignificant variables
GLM2 <- glm(WESBROOK ~ . , family=binomial(logit), data = Wesbrook.est)
summary(GLM2)
1 - (GLM2$deviance/GLM2$null.deviance) # 0.720267
# Creating Log columns
Wesbrook.est$LogTOTLGIVE <- with(Wesbrook.est, log(TOTLGIVE))
# Model after transforming numerical columns to logs
GLM3<- glm(WESBROOK ~ LogTOTLGIVE + PARENT + CHILD + OTHERACT, family = binomial(logit), data = Wesbrook.est)
summary(GLM3)
1 - (GLM3$deviance/GLM3$null.deviance) # 0.7502665
require(xgboost)
require(Matrix)
require(data.table)
require(dplyr)
require(vcd)
library(tidyverse)
rm(list=ls())
# setwd("d:/SGH/PwC/AlexB/")
setwd("~/Desktop/SGH/2 semester/Statistical learning methods/R/PwC project")
#--------------------------------------------------------------------#
#                             GINI                                   #
#--------------------------------------------------------------------#
# Define function
Gini_value <- function(
score, #prediction from model
target #target binary variable (0/1)
){
default <- ifelse(target==0, 'G','B')
d <- data.frame(FY = default, SCORE = score)
s <- table(d[,2],d[,1])
sHeader <- colnames(s)
s <- cbind(s,apply(s,2,cumsum))
colnames(s) <- c(sHeader,paste(sHeader,"_cum",sep=""))
s <- cbind(s , s[,"B_cum"]/max(s[,"B_cum"]) , s[,"G_cum"]/max(s[,"G_cum"]),
diff(c(0,s[,"G_cum"]))/max(s[,"G_cum"]))
colnames(s)<-c(sHeader,
paste(sHeader,"_cum",sep=""),
c("%cum_bad","%cum_good","%good"))
p <- 1:nrow(s)
s <- cbind(s, c( s[1,7] , s[p[-1],7]+s[(p-1)[-1],7]) )
s <- cbind(s, c(0,s[1:(nrow(s)-1),"%cum_bad"]))
colnames(s)[length(colnames(s))] <- "%cum_bad_prev"
auc <- sum(s[,"%good"]*(s[,"%cum_bad"]+s[,"%cum_bad_prev"])*0.5)
gini_value <- abs( 2 * ( auc - 0.5 ) )
return(gini_value)
}
#--------------------------------------------------------------------#
#                        Loading data                                #
#--------------------------------------------------------------------#
PwC <- read.csv("final_data.csv")
#PwC_1<-PwC
PwC$Divorce_number_1000<-as.numeric(as.character(PwC$Divorce_number_1000))
PwC$Average_income<-as.numeric(as.character(PwC$Average_income))
any(is.na(PwC))
sum(is.na(PwC))
