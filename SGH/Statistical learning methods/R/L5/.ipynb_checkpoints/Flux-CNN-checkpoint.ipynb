{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using Flux \n",
    "using Statistics\n",
    "using Flux: onehotbatch, onecold, crossentropy, throttle\n",
    "using Base.Iterators: partition\n",
    "using Printf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Statistics\n",
    "using Distributed\n",
    "using PyPlot\n",
    "\n",
    "@everywhere const TRAIN = (class=UInt8[], image=Matrix{Int32}[])\n",
    "@everywhere const TEST = (class=UInt8[], image=Matrix{Int32}[])\n",
    "\n",
    "@everywhere for (filename, data) in [(\"mnist_train.int\", TRAIN),\n",
    "                                     (\"mnist_test.int\", TEST)]\n",
    "    open(filename) do f\n",
    "        while !eof(f)\n",
    "            c = read(f, UInt8)\n",
    "            v = read(f, 28^2)\n",
    "            push!(data.class, c)\n",
    "            push!(data.image, reshape(v, 28, 28))\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "imshow(TRAIN.image[1])\n",
    "println(TRAIN.class[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@info(\"Loading data set\")\n",
    "\n",
    "imgs = TRAIN.image\n",
    "labels = onehotbatch(TRAIN.class, 0:9)\n",
    "\n",
    "# Partition into batches of size 32\n",
    "train = [(cat(float.(imgs[i])..., dims = 4), labels[:,i])\n",
    "         for i in partition(1:60_000, 32)]\n",
    "train = gpu.(train)\n",
    "\n",
    "# Prepare test set\n",
    "tX = cat(float.(TEST.image)..., dims = 4) |> gpu\n",
    "tY = onehotbatch(TEST.class, 0:9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our model.  We will use a simple convolutional architecture with\n",
    "# three iterations of Conv -> ReLU -> MaxPool, followed by a final Dense\n",
    "# layer that feeds into a softmax probability output.\n",
    "@info(\"Constructing model...\")\n",
    "model = Chain(\n",
    "    # First convolution, operating upon a 28x28 image\n",
    "    Conv((3, 3), 1=>16, pad=(1,1), relu),\n",
    "    x -> maxpool(x, (2,2)),\n",
    "\n",
    "    # Second convolution, operating upon a 14x14 image\n",
    "    Conv((3, 3), 16=>32, pad=(1,1), relu),\n",
    "    x -> maxpool(x, (2,2)),\n",
    "\n",
    "    # Third convolution, operating upon a 7x7 image\n",
    "    Conv((3, 3), 32=>32, pad=(1,1), relu),\n",
    "    x -> maxpool(x, (2,2)),\n",
    "\n",
    "    # Reshape 3d tensor into a 2d one, at this point it should be (3, 3, 32, N)\n",
    "    # which is where we get the 288 in the `Dense` layer below:\n",
    "    x -> reshape(x, :, size(x, 4)),\n",
    "    Dense(288, 10),\n",
    "\n",
    "    # Finally, softmax to get nice probabilities\n",
    "    softmax,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and datasets onto GPU, if enabled\n",
    "train_set = gpu.(train_set)\n",
    "test_set = gpu.(test_set)\n",
    "model = gpu(model)\n",
    "\n",
    "# Make sure our model is nicely precompiled before starting our training loop\n",
    "model(train[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(x, y) = crossentropy(model(x), y)\n",
    "\n",
    "accuracy(x, y) = mean(onecold(model(x)) .== onecold(y))\n",
    "\n",
    "evalcb = throttle(() -> @show(accuracy(tX, tY)), 10)\n",
    "opt = ADAM(params(m))\n",
    "\n",
    "Flux.train!(loss, train, opt, cb = evalcb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": "37C1E4EC1C494A56BCF49DBC22DD4354",
   "lastKernelId": "344083c1-58b3-4ace-babf-6072ed51dd97"
  },
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
