install_tensorflow()
install_tensorflow()
devtools::install_github("rstudio/tensorflow")
# Read in MNIST data
mnist <- dataset_mnist()
install_tensorflow()
library(tensorflow)
install_tensorflow()
library(keras)
library(tensorflow)
sess = tf$Session()
hello <- tf$constant('Hello, TensorFlow!')
sess$run(hello)
# Read in MNIST data
mnist <- dataset_mnist()
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(keras)
mnist <- dataset_mnist()
train_images <- mnist$train$x
train_labels <- mnist$train$y
test_images <- mnist$test$x
test_labels <- mnist$test$y
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(keras)
mnist <- dataset_mnist()
train_images <- mnist$train$x
train_labels <- mnist$train$y
test_images <- mnist$test$x
test_labels <- mnist$test$y
View(mnist)
str(train_images)
str(train_labels)
str(test_images)
str(test_labels)
network <- keras_model_sequential() %>%
layer_dense(units = 512, activation = "relu", input_shape = c(28 * 28)) %>%
layer_dense(units = 10, activation = "softmax")
network %>% compile(
optimizer = "rmsprop",
loss = "categorical_crossentropy",
metrics = c("accuracy")
)
train_images <- array_reshape(train_images, c(60000, 28 * 28))
train_images <- train_images / 255
test_images <- array_reshape(test_images, c(10000, 28 * 28))
test_images <- test_images / 255
train_labels <- to_categorical(train_labels)
test_labels <- to_categorical(test_labels)
View(train_labels)
network %>% fit(train_images, train_labels, epochs = 5, batch_size = 128)
metrics <- network %>% evaluate(test_images, test_labels, verbose = 0)
metrics
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(keras)
mnist <- dataset_mnist()
train_images <- mnist$train$x
train_labels <- mnist$train$y
test_images <- mnist$test$x
test_labels <- mnist$test$y
system.time(m <- matrix(rnorm(10000^2), ncol=10000))
m
system.time(m[lower.tri(m)] <- 0)
system.time(sum(m))
View(m)
rm(list=ls())
require(xgboost)
data(agaricus.train, package='xgboost')
data(agaricus.test, package='xgboost')
train <- agaricus.train
test <- agaricus.test
str(train)
dim(train$data)
dim(test$data)
library(BCA)
library(relimp)
library(car)
library(RcmdrMisc)
library(foreign)
library(corrplot)
library(dplyr)
# Loading data
Wesbrook <- read.dbf("~/Desktop/SGH/2 semester/Big data/labs/4/Wesbrook.dbf", as.is=FALSE)
variable.summary(Wesbrook)
# Removing some variables
Wesbrook <- within(Wesbrook, {
ID <- NULL
INDUPDT <- NULL
BIGBLOCK <- NULL # 1 level factor variable
MARITAL <- NULL
MAJOR1 <- NULL
})
# Creating numerical variable from factor variable WESBROOK
Wesbrook <- within(Wesbrook, {
WESBROOK <- Recode(WESBROOK, '"Y"=1; "N"=0', as.factor=FALSE)
})
# Creating estimation and validation subsets
set.seed(323)
Wesbrook$Sample <- create.samples(Wesbrook, est = 0.7, val = 0.3)
# Excluding all NA from Wesbrook
Wesbrook <- na.exclude(Wesbrook)
# Checking if there are still some NA values
any(is.na(Wesbrook))
# Generalized linear model after excluding some variables
GLM <- glm(WESBROOK ~ . , family=binomial(logit), data=Wesbrook)
summary(GLM)
variable.summary(GLM)
variable.summary(Wesbrook)
summary(GLM)
Wesbrook$DEPT1 <- as.numeric(Wesbrook$DEPT1)
Wesbrook$FACULTY1 <- as.numeric(Wesbrook$FACULTY1)
# Generalized linear model after excluding some variables
GLM <- glm(WESBROOK ~ . , family=binomial(logit), data=Wesbrook)
summary(GLM)
variable.summary(Wesbrook)
# R2 McFadden value
1 - (GLM$deviance/GLM$null.deviance) # 0.7724513
# Selecting 70% of observations for training model
Wesbrook.est <- Wesbrook %>% filter(Sample == "Estimation")
# Selecting only statistically significant variables and dependent one
Wesbrook.est <- Wesbrook.est[, c("TOTLGIVE", "PARENT", "CHILD", "OTHERACT", "WESBROOK")]
rm(list=ls())                      # clean environment
if(!is.null(dev.list())) dev.off() # clean all plots
cat("\014")                        # clean console
# Loading data
Wesbrook <- read.dbf("~/Desktop/SGH/2 semester/Big data/labs/4/Wesbrook.dbf", as.is=FALSE)
variable.summary(Wesbrook)
# Removing some variables
Wesbrook <- within(Wesbrook, {
ID <- NULL
INDUPDT <- NULL
BIGBLOCK <- NULL # 1 level factor variable
MARITAL <- NULL
MAJOR1 <- NULL
})
# Creating numerical variable from factor variable WESBROOK
Wesbrook <- within(Wesbrook, {
WESBROOK <- Recode(WESBROOK, '"Y"=1; "N"=0', as.factor=FALSE)
})
# Creating estimation and validation subsets
set.seed(323)
Wesbrook$Sample <- create.samples(Wesbrook, est = 0.7, val = 0.3)
# Excluding all NA from Wesbrook
Wesbrook <- na.exclude(Wesbrook)
# Checking if there are still some NA values
any(is.na(Wesbrook))
# Generalized linear model after excluding some variables
GLM <- glm(WESBROOK ~ . , family=binomial(logit), data=Wesbrook)
summary(GLM)
# R2 McFadden value
1 - (GLM$deviance/GLM$null.deviance) # 0.7724513
# Selecting 70% of observations for training model
Wesbrook.est <- Wesbrook %>% filter(Sample == "Estimation")
# Selecting only statistically significant variables and dependent one
Wesbrook.est <- Wesbrook.est[, c("TOTLGIVE", "PARENT", "CHILD", "OTHERACT", "WESBROOK")]
# Generalized linear model after excluding all insignificant variables
GLM2 <- glm(WESBROOK ~ . , family=binomial(logit), data = Wesbrook.est)
summary(GLM2)
1 - (GLM2$deviance/GLM2$null.deviance) # 0.720267
# Creating Log columns
Wesbrook.est$LogTOTLGIVE <- with(Wesbrook.est, log(TOTLGIVE))
# Model after transforming numerical columns to logs
GLM3<- glm(WESBROOK ~ LogTOTLGIVE + PARENT + CHILD + OTHERACT, family = binomial(logit), data = Wesbrook.est)
summary(GLM3)
1 - (GLM3$deviance/GLM3$null.deviance) # 0.7502665
library(BCA)
library(relimp)
library(car)
library(RcmdrMisc)
# Loading CCS dataset from BCA package
data(CCS, package="BCA")
# Creating validation and estimation subsets
set.seed(321)
CCS$Sample <- create.samples(CCS, est = 0.7, val = 0.3)
View(CCS)
# Creating numerical variable from factor variable MonthsGive
CCS <- within(CCS, {
MonthGive.Num <- Recode(MonthGive, '"Yes"=1; "No"=0', as.factor=FALSE) # Recode changes values from yes/no to 1/0
})
# Variables distribution chart
scatterplot(MonthGive.Num~AveDonAmt, reg.line=lm, smooth=TRUE,
id.n = 2, boxplots='xy', span=0.5, data=CCS)
# Means chart for Region variable
with(CCS, plotMeans(MonthGive.Num, Region, error.bars="none")) # plotmeans plots mean values of variables
# Reorganizing levels of Region factor variable
CCS$NRegion <- relabel.factor(CCS$Region, new.labels=c('NR1','NR1','NR1',
'NR2','NR2','NR2'))
with(CCS, plotMeans(MonthGive.Num, NRegion))
# Generalized linear model
GLM.2 <- glm(MonthGive ~ Age20t29 +Age20t39 + Age60pls + Age70pls + Age80pls +
AveDonAmt + AveIncEA + DonPerYear + EngPrmLang + FinUnivP + LastDonAmt +
NewDonor+NRegion, family=binomial(logit), data=CCS)
variable.summary(GLM.2)
variable.summary(CCS)
library(BCA)
library(relimp)
library(car)
library(RcmdrMisc)
library(foreign)
library(corrplot)
library(dplyr)
rm(list=ls())                      # clean environment
if(!is.null(dev.list())) dev.off() # clean all plots
cat("\014")                        # clean console
# Loading data
Wesbrook <- read.dbf("~/Desktop/SGH/2 semester/Big data/labs/4/Wesbrook.dbf", as.is=FALSE)
variable.summary(Wesbrook)
# Removing some variables
Wesbrook <- within(Wesbrook, {
ID <- NULL
INDUPDT <- NULL
BIGBLOCK <- NULL # 1 level factor variable
MARITAL <- NULL
MAJOR1 <- NULL
})
# Removing some variables
Wesbrook <- within(Wesbrook, {
ID <- NULL
INDUPDT <- NULL
BIGBLOCK <- NULL # 1 level factor variable
MARITAL <- NULL
MAJOR1 <- NULL
})
variable.summary(Wesbrook)
PARENT <- Recode(PARENT, '"Y"=1; "N"=0', as.factor=FALSE)
View(Wesbrook)
# Creating numerical variable from factor variable WESBROOK
Wesbrook <- within(Wesbrook, {
WESBROOK <- Recode(WESBROOK, '"Y"=1; "N"=0', as.factor=FALSE)
PARENT <- Recode(PARENT, '"Y"=1; "N"=0', as.factor=FALSE)
})
OTHERACT <- Recode(OTHERACT, '"Y"=1; "N"=0', as.factor=FALSE)
# Creating numerical variable from factor variable WESBROOK
Wesbrook <- within(Wesbrook, {
WESBROOK <- Recode(WESBROOK, '"Y"=1; "N"=0', as.factor=FALSE)
PARENT <- Recode(PARENT, '"Y"=1; "N"=0', as.factor=FALSE)
CHILD <- Recode(CHILD, '"Y"=1; "N"=0', as.factor=FALSE)
SPOUSE <- Recode(SPOUSE, '"Y"=1; "N"=0', as.factor=FALSE)
SEX <- Recode(SEX, '"Y"=1; "N"=0', as.factor=FALSE)
FACSTAFF <- Recode(FACSTAFF, '"Y"=1; "N"=0', as.factor=FALSE)
ATHLTCS <- Recode(ATHLTCS, '"Y"=1; "N"=0', as.factor=FALSE)
OTHERACT <- Recode(OTHERACT, '"Y"=1; "N"=0', as.factor=FALSE)
})
# Creating estimation and validation subsets
set.seed(323)
Wesbrook$Sample <- create.samples(Wesbrook, est = 0.7, val = 0.3)
# Excluding all NA from Wesbrook
Wesbrook <- na.exclude(Wesbrook)
# Checking if there are still some NA values
any(is.na(Wesbrook))
# Generalized linear model after excluding some variables
GLM <- glm(WESBROOK ~ . , family=binomial(logit), data=Wesbrook)
summary(GLM)
# R2 McFadden value
1 - (GLM$deviance/GLM$null.deviance) # 0.7724513
rm(list=ls())                      # clean environment
if(!is.null(dev.list())) dev.off() # clean all plots
cat("\014")                        # clean console
# Loading data
Wesbrook <- read.dbf("~/Desktop/SGH/2 semester/Big data/labs/4/Wesbrook.dbf", as.is=FALSE)
# Removing some variables
Wesbrook <- within(Wesbrook, {
ID <- NULL
INDUPDT <- NULL
BIGBLOCK <- NULL # 1 level factor variable
MARITAL <- NULL
MAJOR1 <- NULL
})
# Creating numerical variable from factor variable WESBROOK
Wesbrook <- within(Wesbrook, {
WESBROOK <- Recode(WESBROOK, '"Y"=1; "N"=0', as.factor=FALSE)
# PARENT <- Recode(PARENT, '"Y"=1; "N"=0', as.factor=FALSE)
# CHILD <- Recode(CHILD, '"Y"=1; "N"=0', as.factor=FALSE)
# SPOUSE <- Recode(SPOUSE, '"Y"=1; "N"=0', as.factor=FALSE)
# SEX <- Recode(SEX, '"Y"=1; "N"=0', as.factor=FALSE)
# FACSTAFF <- Recode(FACSTAFF, '"Y"=1; "N"=0', as.factor=FALSE)
# ATHLTCS <- Recode(ATHLTCS, '"Y"=1; "N"=0', as.factor=FALSE)
# OTHERACT <- Recode(OTHERACT, '"Y"=1; "N"=0', as.factor=FALSE)
})
rm(list=ls())                      # clean environment
if(!is.null(dev.list())) dev.off() # clean all plots
cat("\014")                        # clean console
# Loading data
Wesbrook <- read.dbf("~/Desktop/SGH/2 semester/Big data/labs/4/Wesbrook.dbf", as.is=FALSE)
# Removing some variables
Wesbrook <- within(Wesbrook, {
ID <- NULL
INDUPDT <- NULL
BIGBLOCK <- NULL # 1 level factor variable
MARITAL <- NULL
MAJOR1 <- NULL
})
# Creating estimation and validation subsets
set.seed(323)
Wesbrook$Sample <- create.samples(Wesbrook, est = 0.7, val = 0.3)
# Excluding all NA from Wesbrook
Wesbrook <- na.exclude(Wesbrook)
# Checking if there are still some NA values
any(is.na(Wesbrook))
# Generalized linear model after excluding some variables
GLM <- glm(WESBROOK ~ . , family=binomial(logit), data=Wesbrook)
summary(GLM)
# R2 McFadden value
1 - (GLM$deviance/GLM$null.deviance) # 0.7724513
rm(list=ls())                      # clean environment
if(!is.null(dev.list())) dev.off() # clean all plots
cat("\014")                        # clean console
# Loading data
Wesbrook <- read.dbf("~/Desktop/SGH/2 semester/Big data/labs/4/Wesbrook.dbf", as.is=FALSE)
# Removing some variables
Wesbrook <- within(Wesbrook, {
ID <- NULL
INDUPDT <- NULL
BIGBLOCK <- NULL # 1 level factor variable
MARITAL <- NULL
MAJOR1 <- NULL
})
# Creating numerical variable from factor variable WESBROOK
Wesbrook <- within(Wesbrook, {
WESBROOK <- Recode(WESBROOK, '"Y"=1; "N"=0', as.factor = F)
})
# Creating estimation and validation subsets
set.seed(323)
Wesbrook$Sample <- create.samples(Wesbrook, est = 0.7, val = 0.3)
# Excluding all NA from Wesbrook
Wesbrook <- na.exclude(Wesbrook)
# Checking if there are still some NA values
any(is.na(Wesbrook))
# Generalized linear model after excluding some variables
GLM <- glm(WESBROOK ~ . , family=binomial(logit), data=Wesbrook)
summary(GLM)
# R2 McFadden value
1 - (GLM$deviance/GLM$null.deviance) # 0.7724513
# Selecting 70% of observations for training model
Wesbrook.est <- Wesbrook %>% filter(Sample == "Estimation")
# Selecting only statistically significant variables and dependent one
Wesbrook.est <- Wesbrook.est[, c("TOTLGIVE", "PARENT", "CHILD", "OTHERACT", "WESBROOK")]
# Generalized linear model after excluding all insignificant variables
GLM2 <- glm(WESBROOK ~ . , family=binomial(logit), data = Wesbrook.est)
summary(GLM2)
1 - (GLM2$deviance/GLM2$null.deviance) # 0.720267
# Creating Log columns
Wesbrook.est$LogTOTLGIVE <- with(Wesbrook.est, log(TOTLGIVE))
# Model after transforming numerical columns to logs
GLM3<- glm(WESBROOK ~ LogTOTLGIVE + PARENT + CHILD + OTHERACT, family = binomial(logit), data = Wesbrook.est)
summary(GLM3)
1 - (GLM3$deviance/GLM3$null.deviance) # 0.7502665
for (i in 1:10) {
print(i)
}
library(BCA)
library(relimp)
library(car)
library(RcmdrMisc)
library(foreign)
library(corrplot)
library(dplyr)
rm(list=ls())                      # clean environment
if(!is.null(dev.list())) dev.off() # clean all plots
cat("\014")                        # clean console
# Loading data
Wesbrook <- read.dbf("~/Desktop/SGH/2 semester/Big data/labs/4/Wesbrook.dbf", as.is=FALSE)
variable.summary(Wesbrook)
rm(list=ls())                      # clean environment
if(!is.null(dev.list())) dev.off() # clean all plots
cat("\014")                        # clean console
# Loading data
Wesbrook <- read.dbf("~/Desktop/SGH/2 semester/Big data/labs/4/Wesbrook.dbf", as.is=FALSE)
variable.summary(Wesbrook)
View(Wesbrook)
summary(Wesbrook)
summarise(Wesbrook)
?variable.summary
?train
#SET WORKING DIRECTORY
setwd("~/Desktop/SGH/2 semester/Spatial Econometrics")
# clear the workspace, plots and console
rm(list = ls())
if(!is.null(dev.list())) dev.off()
cat("\014")
library(sp)
library(spdep)
#SET WORKING DIRECTORY
setwd("~/Desktop/SGH/2 semester/Spatial Econometrics")
# clear the workspace, plots and console
rm(list = ls())
if(!is.null(dev.list())) dev.off()
cat("\014")
library(sp)
library(spdep)
#Scripts 5-6 continued (final workspace and packages should be loaded)
map <-
readOGR(dsn = "spatial_data",
layer = "spatial_final",
stringsAsFactors = F)
map <- spTransform(map, "+proj=longlat")
#SET WORKING DIRECTORY
setwd("~/Desktop/SGH/2 semester/Spatial Econometrics")
# clear the workspace, plots and console
rm(list = ls())
if(!is.null(dev.list())) dev.off()
cat("\014")
library(sp)
library(spdep)
#Scripts 5-6 continued (final workspace and packages should be loaded)
map <-
readOGR(dsn = "spatial_data",
layer = "spatial_final",
stringsAsFactors = F)
library(rgdal)
library(sp)
library(spdep)
#Scripts 5-6 continued (final workspace and packages should be loaded)
map <-
readOGR(dsn = "spatial_data",
layer = "spatial_final",
stringsAsFactors = F)
map <- spTransform(map, "+proj=longlat")
plot(map)
mod.SLX1 <- lmSLX(l_Deaths ~ Fertlty, listw = W1_list, data = map, zero.policy = T)
mod.SLX1 <- lmSLX(Deaths ~ Fertlty, listw = W1_list, data = map, zero.policy = T)
cont1 <- poly2nb(map, queen = T)
W1_list <- nb2listw(cont1, style = "W", zero.policy = T)
lm.morantest(mod.lin, W1_list, alternative = "greater", zero.policy = T)
mod.SLX1 <- lmSLX(Deaths ~ Fertlty, listw = W1_list, data = map, zero.policy = T)
summary(mod.SLX1)
mod.SLX1 <- lmSLX(Deaths ~ Fertlty, listw = W1_list, data = map, zero.policy = T)
impacts.SLX <- impacts(SLX, zstats = TRUE, R = 200)
SLX <- lmSLX(Deaths ~ Fertlty, listw = W1_list, data = map, zero.policy = T)
impacts.SLX <- impacts(SLX, zstats = TRUE, R = 200)
summary(impacts.SLX)
#Effects from SDEM
SDEM <- errorsarlm(Deaths ~ Fertlty, listw = W1_list, data = map, etype = "emixed", zero.policy = T)
impacts.SDEM <- impacts(SDEM, listw = W_list, zstats = TRUE, R = 200)
summary(impacts.SDEM)
# ------- Models with spatial autoregression -------
# Effects from SAR
SAR <- lagsarlm(Deaths ~ Fertlty, listw = W1_list, data = map, type = "Durbin", zero.policy = T)
impacts.SAR <- impacts(SAR, listw = W_list, zstats = TRUE, R = 200)
impacts.SAR <- impacts(SAR, listw = W1_list, zstats = TRUE, R = 200)
summary(impacts.SAR)
# Confidence intervals around estimated effects
HPDinterval.lagImpact(impacts.SAR, prob = 0.95, choice = "direct")
HPDinterval.lagImpact(impacts.SAR, prob = 0.95, choice = "indirect")
HPDinterval.lagImpact(impacts.SAR, prob = 0.95, choice = "total")
# Spatial multipliers matrix M
W <- listw2mat(W1_list)
N <- dim(W)[1]
rho <- SAR$rho
M <- solve(diag(N) - rho  * W)
# Let us focus on one regressor: wages and compute the standard errors of its spatial multipliers
# METHOD 1: DELTA
b_wyn <- SAR$coefficients["wynagrodzenie"]
# Let us focus on one regressor: wages and compute the standard errors of its spatial multipliers
# METHOD 1: DELTA
b_wyn <- SAR$coefficients["Deaths"]
View(SAR)
# Let us focus on one regressor: wages and compute the standard errors of its spatial multipliers
# METHOD 1: DELTA
b_wyn <- SAR$coefficients["Fertlty"]
S.b_wyn <- M * b_wyn
partial.Sb_wyn.rho <- M %*% W %*% M * b_wyn
partial.Sb_wyn.b_wyn <- M
VCV <- SAR$fdHess
VCV.rho.b_wyn <- solve(matrix(c(VCV["rho", "rho"], VCV["wynagrodzenie", "rho"],
VCV ["rho", "wynagrodzenie"], VCV["wynagrodzenie", "wynagrodzenie"]),
nrow = 2))
VCV.rho.b_wyn <- solve(matrix(c(VCV["rho", "rho"], VCV["Fertlty", "rho"],
VCV ["rho", "Fertlty"], VCV["Fertlty", "Fertlty"]),
nrow = 2))
S.b_wyn.SE <- matrix(NA, nrow = N, ncol = N)
for(i in 1:N){
S.b_wyn.gradients <- cbind(partial.Sb_wyn.rho[, i], partial.Sb_wyn.b_wyn[, i])
S.b_wyn.var <- S.b_wyn.gradients %*% VCV.rho.b_wyn %*% t(S.b_wyn.gradients)
S.b_wyn.var <- matrix(S.b_wyn.var, ncol = N)
S.b_wyn.SE[, i] <- diag(sqrt(S.b_wyn.var))
}
# Effects from SARAR
SARAR <- sacsarlm(Deaths ~ Fertlty, listw = W1_list, data = map, zero.policy = T)
impacts.SARAR <- impacts(SARAR, listw = W_list, zstats = TRUE, R = 200)
# Effects from SDM
SDM <- lagsarlm(Deaths ~ Fertlty, listw = W1_list, data = map, type = "Durbin", zero.policy = T)
HPDinterval.lagImpact(impacts.SDM, prob = 0.95, choice = "direct")
HPDinterval.lagImpact(impacts.SDM, prob = 0.95, choice = "direct")
# Effects from SDM
SDM <- lagsarlm(l_Deaths ~ Fertlty, listw = W1_list, data = map, type = "Durbin", zero.policy = T)
impacts.SDM <- impacts(SDM, listw = W_list, zstats = TRUE, R = 200)
# Effects from SDM
SDM <- lagsarlm(Deaths ~ Fertlty, listw = W1_list, data = map, type = "Durbin", zero.policy = T)
impacts.SDM <- impacts(SDM, listw = W_list, zstats = TRUE, R = 200)
impacts.SDM <- impacts(SDM, listw = W1_list, zstats = TRUE, R = 200)
HPDinterval.lagImpact(impacts.SDM, prob = 0.95, choice = "direct")
HPDinterval.lagImpact(impacts.SDM, prob = 0.95, choice = "indirect")
HPDinterval.lagImpact(impacts.SDM, prob = 0.95, choice = "total")
summary(impacts.SLX)
summary(impacts.SDEM)
summary(impacts.SAR)
# Confidence intervals around estimated effects
HPDinterval.lagImpact(impacts.SAR, prob = 0.95, choice = "direct")
HPDinterval.lagImpact(impacts.SAR, prob = 0.95, choice = "indirect")
HPDinterval.lagImpact(impacts.SAR, prob = 0.95, choice = "total")
summary(impacts.SARAR)
impacts.SARAR <- impacts(SARAR, listw = W_list, zstats = TRUE, R = 200)
impacts.SARAR <- impacts(SARAR, listw = W1_list, zstats = TRUE, R = 200)
summary(impacts.SARAR)
HPDinterval.lagImpact(impacts.SARAR, prob = 0.95, choice = "direct")
HPDinterval.lagImpact(impacts.SARAR, prob = 0.95, choice = "indirect")
HPDinterval.lagImpact(impacts.SARAR, prob = 0.95, choice = "total")
summary(impacts.SDM)
HPDinterval.lagImpact(impacts.SDM, prob = 0.95, choice = "direct")
HPDinterval.lagImpact(impacts.SDM, prob = 0.95, choice = "indirect")
HPDinterval.lagImpact(impacts.SDM, prob = 0.95, choice = "total")
