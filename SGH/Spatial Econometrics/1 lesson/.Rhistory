labs(x = "fat", y = "rating")
# rating with sugar and calories
gg = ggplot(data = cereal, aes(x = sugars, y = calories, col = rating)) +
geom_jitter(data = cereal, aes(sugars, calories, col = rating)) +
labs(x = "Sugar", y = "Calories") +
geom_smooth(method = "lm", se = FALSE, col = 'black') +
theme_bw()
gg
ggplotly(gg)
# bar chart: top 10 companies by rating
bar.cereal <- cereal %>%
arrange(desc(rating)) %>%
head(10) %>%
mutate(name = fct_reorder(name, rating)) %>%
select(name, rating)
ggplot(bar.cereal, aes(name, rating, fill = name)) +
geom_col() +
coord_flip() +
theme(legend.position = "none")
# one more bar chart
ggplot(bar.cereal, aes(x = name, y = rating)) +
geom_bar(stat = "identity", width = .5, fill = "tomato3") +
labs(title = "Ordered Bar Chart",
subtitle = "Make Vs Avg. Mileage",
caption = "source: mpg") +
theme(axis.text.x = element_text(angle = 65, vjust = 0.6))
# vars of top 10 companies
top10 <- cereal %>%
arrange(desc(rating)) %>%
head(10) %>%
mutate(name = fct_reorder(name, rating))
ggplot(top10, aes(x = name, y = rating)) +
geom_bar(stat = "identity", width = .5, fill = "tomato3") +
labs(title = "Ordered Bar Chart") +
theme(axis.text.x = element_text(angle = 65, vjust = 0.6))
# Manufacturers to weights
ggplot() +
geom_point(cereal, mapping = aes(
x = mfr,
y = weight,
color = mfr,
size = 3
)) +
labs(x = "Manufacturer", y = "Ounce") +
ggtitle("Manufacturers use Different Weights for One Serving")
# Manufacturers to cups
ggplot() +
geom_point(cereal, mapping = aes(
x = mfr,
y = cups,
color = mfr,
size = 3
)) +
labs(x = "Manufacturer", y = "Cup") +
ggtitle("Manufacturers use Different Cups for One Serving")
# creting var with only numeric columns from cereal data
cereal.numeric <- cereal[, sapply(cereal, is.numeric)]
cereal.numeric.scat <- cereal.numeric
cereal.numeric.scat$weight <- NULL
cereal.numeric.scat$cups <- NULL
# ???
mean(cereal$calories)
summary(cereal)
cereal.box <- cereal.numeric
cereal.box <-
gather(cereal.box, calories, protein, fat, sodium, fiber,
carbo, sugars, potass, vitamins,
key = "components", value = "value")
box <- ggplot(cereal.box, aes(factor(components), value))
box + geom_boxplot(aes(fill = components)) +
scale_y_continuous(limits = c(0, 250)) +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
bar <- ggplot(cereal.numeric, aes(sugars))
bar + geom_bar(aes(fill = sugars)) +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# example of density plot
ggplot(cereal.numeric, aes(x=calories))+
geom_density(color="darkblue", fill="lightblue")
# Shiny ------------------------------------------------------------------------
ui <-
navbarPage(
theme = shinytheme("yeti"),
title = h4("Cereals analysis"),
tabPanel(
"Rating with comparison of variables",
selectInput("x", "choose x", colnames(cereal.numeric.scat)),
selectInput("y", "choose y", colnames(cereal.numeric.scat)),
plotlyOutput("scat")
),
tabPanel(
"Distribution",
selectInput("distribution", "choose var", colnames(cereal.numeric)),
plotlyOutput("hist")
),
tabPanel("Top 10 companies",
plotOutput("bar")),
tabPanel(
"Cups and weights",
br(),
h1("Same manufacturers use different cups and
weights for one serving "),
br(),
plotOutput("point1"),
br(),
plotOutput("point2")
),
tabPanel(
"Data Table with the underlying Data",
DT::dataTableOutput("tableDT")
),
tabPanel(
"Documentation",
h1("77 Cereals"),
br(),
strong("Context"),
br(),
p(
"If you like to eat cereal, do yourself a favor and avoid this
dataset at all costs. After seeing these data it will never
be the same for me to eat Fruity Pebbles again."
),
br(),
strong("Sources"),
br(),
"The original source of dataset can be found",
a("here", href = "https://perso.telecom-paristech.fr/eagan/class/igr204/datasets"),
br(),
"In this project was used cleaned dataset from",
a("kaggle", href = "https://www.kaggle.com/crawford/80-cereals/home")
)
)
server <- function(input, output) {
x <- reactive({
cereal.numeric.scat[, input$x]
})
y <- reactive({
cereal.numeric.scat[, input$y]
})
dist <- reactive({
cereal.numeric[, input$distribution]
})
output$scat = renderPlotly({
scat <- ggplot(data = cereal.numeric, aes(x(), y(),
col = rating)) +
geom_jitter(data = cereal.numeric, aes(x(), y(),
col = rating), size = 3) +
labs(x = input$x, y = input$y) +
geom_smooth(method = "lm",
se = FALSE,
# se shows small field around regression line
col = 'tomato3', size = 1.5) +
theme_gray()  +
scale_colour_gradient2()
ggplotly(scat)
})
output$hist = renderPlotly({
hist <- ggplot(data = cereal.numeric, aes(dist())) +
geom_histogram(color = "blue", fill = "lightgreen") +
labs(x = input$distribution)
ggplotly(hist)
})
output$bar = renderPlot({
ggplot(bar.cereal, aes(x = name, y = rating)) +
geom_bar(stat = "identity",
width = .5,
fill = "tomato3") +
theme(axis.text.x = element_text(angle = 45, vjust = 0.6))
})
output$point1 = renderPlot({
ggplot() +
geom_point(cereal, mapping = aes(
x = mfr,
y = weight,
color = mfr,
size = 3
)) +
labs(x = "Manufacturer", y = "Ounce") +
ggtitle("Manufacturers use Different Weights for One Serving")
})
output$point2 = renderPlot({
ggplot() +
geom_point(cereal, mapping = aes(
x = mfr,
y = cups,
color = mfr,
size = 3
)) +
labs(x = "Manufacturer", y = "Cup") +
ggtitle("Manufacturers use Different Cups for One Serving")
})
output$tableDT <- DT::renderDataTable(DT::datatable(cereal))
}
shinyApp(ui, server)
install.packages("keras")
install.packages("kerasR")
getwd()
> install.packages("kerasR")
install.packages("kerasR")
install.packages("keras")
setwd("~/Desktop")
install.packages("keras")
install.packages("kerasR")
library(ggplot2)
library(dplyr)
# psavert to date
# 1) with qplot
qplot(date, psavert, data = economics)
# 2) with ggplot2
econ.point <- ggplot(economics)
lmcoef <- coef(lm(psavert ~ date, economics))
econ.point + geom_point(aes(x = date, y = psavert)) +
geom_abline(intercept = lmcoef[1], slope = lmcoef[2])
# unemployment to population
econ.unemp <- ggplot(economics)
lmcoef <- coef(lm(unemploy ~ pop, economics))
econ.unemp + geom_point(aes(x = pop, y = unemploy), colour = "brown") +
geom_abline(intercept = lmcoef[1], slope = lmcoef[2])
# distributiopn of uempmed (median duration of unemployment, in weeks)
econ.hist <- ggplot(economics, aes(uempmed))
econ.hist + geom_histogram(color = "blue", fill = "yellow")
econ.filtered <- economics %>%
filter(psavert > 6, pce > 10000) %>%
arrange(desc(pce)) %>%
head(10)
ggplot(econ.filtered, aes(
x = pce,
y = pop,
size = psavert,
label = date
), guide = FALSE) +
geom_point(colour = "blue",
fill = "darkgreen",
shape = 21) + scale_size_area(max_size = 16) +
scale_x_continuous() +
scale_y_continuous() +
geom_text(size = 3) +
theme_bw()
library(ggplot2movies)
library(dplyr)
# histogram of movies' length
gmovies.hist <- ggplot(data = movies, aes(length))
library(ggplot)
library(ggplot2)
library(ggplot2movies)
library(ggplot2)
library(ggplot2movies)
library(dplyr)
library(tidyverse)
# histogram of movies' length
gmovies.hist <- ggplot(data = movies, aes(length))
gmovies.hist + geom_histogram(color = "blue", fill = "lightgreen") +
scale_x_continuous(limits = c(0, 200))
# top 10 movies
top10 <- movies %>%
arrange(desc(rating)) %>%
head(10) %>%
mutate(title = fct_reorder(title, rating))
top10.bar <- ggplot(top10, aes(title, rating, fill = "dar green"))
top10.bar +
geom_col() +
theme(legend.position = "none") +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
# dividing by genres
movies <- within (movies, {
Genre = ifelse (Action == 1, "Action" ,
ifelse(Animation == 1,'Animation',
ifelse(Comedy == 1, "Comedy",
ifelse(Drama == 1, "Drama",
ifelse(Documentary == 1, 'Documentary',
ifelse(Romance == 1, "Romance",
ifelse(Short==1, 'Short', '')))))))})
# boxplot
movies.box <- ggplot(movies, aes(factor(Genre), rating))
movies.box + geom_boxplot(aes(fill = Genre)) +
scale_y_continuous(limits = c(5, 10)) +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
# facet wrap of bar chart for movies after 1920
genres.bar <- movies %>%
filter(year >= 1920)
movies.bar <- ggplot(genres.bar, aes(year))
movies.bar + geom_bar(aes(fill = Genre)) +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
facet_wrap( ~ Genre)
# bars by genres
movies.bar1 <- ggplot(genres.bar, aes(Genre))
movies.bar1 + geom_bar(aes(fill = Genre)) +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
library(ggplot2)
library(ggplot2movies)
library(dplyr)
library(tidyverse)
# histogram of movies' length
gmovies.hist <- ggplot(data = movies, aes(length))
gmovies.hist + geom_histogram(color = "blue", fill = "lightgreen") +
scale_x_continuous(limits = c(0, 200))
# top 10 movies
top10 <- movies %>%
arrange(desc(rating)) %>%
head(10) %>%
mutate(title = fct_reorder(title, rating))
# dividing by genres
movies <- within (movies, {
Genre = ifelse (Action == 1, "Action" ,
ifelse(Animation == 1,'Animation',
ifelse(Comedy == 1, "Comedy",
ifelse(Drama == 1, "Drama",
ifelse(Documentary == 1, 'Documentary',
ifelse(Romance == 1, "Romance",
ifelse(Short==1, 'Short', '')))))))})
# boxplot
movies.box <- ggplot(movies, aes(factor(Genre), rating))
movies.box + geom_boxplot(aes(fill = Genre)) +
scale_y_continuous(limits = c(5, 10)) +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
# facet wrap of bar chart for movies after 1920
genres.bar <- movies %>%
filter(year >= 1920)
movies.bar <- ggplot(genres.bar, aes(year))
movies.bar + geom_bar(aes(fill = Genre)) +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
facet_wrap( ~ Genre)
# bars by genres
movies.bar1 <- ggplot(genres.bar, aes(Genre))
movies.bar1 + geom_bar(aes(fill = Genre)) +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
iris
names(iris)
install.packages("ggvis")
# Load in `ggvis`
library(ggvis)
# Iris scatter plot
iris %>% ggvis(~Sepal.Length, ~Sepal.Width, fill = ~Species) %>% layer_points()
iris %>% ggvis(~Sepal.Length, ~Sepal.Width, fill = ~Species)
iris %>% ggvis(~Petal.Length, ~Petal.Width, fill = ~Species) %>% layer_points()
# Overall correlation `Petal.Length` and `Petal.Width`
cor(iris$Petal.Length, iris$Petal.Width)
# Return values of `iris` levels
x=levels(iris$Species)
# Print Setosa correlation matrix
print(x[1])
cor(iris[iris$Species==x[1],1:4])
View(iris)
print(x[2])
cor(iris[iris$Species==x[1],1:4])
# Print Versicolor correlation matrix
print(x[2])
cor(iris[iris$Species==x[2],1:4])
# Print Virginica correlation matrix
print(x[3])
cor(iris[iris$Species==x[3],1:4])
iris$Species==x[1]
x
# Return first 5 lines of `iris`
head(iris)
# Return structure of `iris`
str(iris)
# Division of `Species`
table(iris$Species)
# Percentual division of `Species`
round(prop.table(table(iris$Species)) * 100, digits = 1)
# Summary overview of `iris`
summary(....)
# Summary overview of `iris`
summary(iris)
# Refined summary overview
summary(iris[c("Petal.Width", "Sepal.Width")])
install.packages("class")
library(class)
any(grepl("clas", installed.packages()))
any(grepl("class", installed.packages()))
# Summary overview of `iris`
summary(iris)
lapply(iris)
# Build your own `normalize()` function
normalize <- function(x) {
num <- x - min(x)
denom <- max(x) - min(x)
return (num/denom)
}
# Normalize the `iris` data
iris_norm <- as.data.frame(lapply(iris[1:4], normalize))
# Summarize `iris_norm`
summary(iris_norm)
library(devtools)
library(shiny)
library(shinythemes)
library(DT)
library(ggplot2)
library(plotly)
library(tidyverse)
library(dplyr)
library(reshape2)
library(ggcorrplot)
library(lattice)
cereal <- read.csv("cereal.csv")
cereal <- read.csv("/User/Valkoiset/Desktop/cereals/cereal.csv")
cereal <- read.csv("User/Valkoiset/Desktop/cereals/cereal.csv")
cereal <- read.csv("Users/Valkoiset/Desktop/cereals/cereal.csv")
cereal <- read.csv("/Users/Valkoiset/Desktop/cereals/cereal.csv")
cereal$shelf <- NULL
attach(cereal)
# DATA PREPARATION
# checking  that these data are numeric and not something that doesn't work
sapply(cereal, mode)
sapply(cereal, class)
# Create a list of matrices
MyList <- list(A,B,C)
# Extract the 2nd column from `MyList` with the selection operator `[` with `lapply()`
lapply(MyList,"[", , 2)
MyList
lapply(MyList,"[", 1, 2)
set.seed(1234)
ind <- sample(2, nrow(iris), replace=TRUE, prob=c(0.67, 0.33))
ind
# Compose training set
iris.training <- iris[ind==1, 1:4]
iris.training
# Inspect training set
head(iris.training)
# Compose test set
iris.test <- iris[ind==2, 1:4]
iris.test
# Inspect test set
head(iris.test)
# Compose test set
iris.test <- iris[ind==2, 1:4]
iris.test
# Inspect test set
head(iris.test)
# Build the model
iris_pred <- knn(train = iris.training, test = iris.test, cl = iris.trainLabels, k=3)
# Inspect test set
head(iris.test)
# Compose `iris` training labels
iris.trainLabels <- iris[ind==1,5]
# Inspect result
print(iris.trainLabels)
# Compose `iris` test labels
iris.testLabels <- iris[ind==2, 5]
# Inspect result
print(iris.testLabels)
# Build the model
iris_pred <- knn(train = iris.training, test = iris.test, cl = iris.trainLabels, k=3)
# Inspect `iris_pred`
iris_pred
# Put `iris.testLabels` in a data frame
irisTestLabels <- data.frame(iris.testLabels)
# Merge `iris_pred` and `iris.testLabels`
merge <- data.frame(iris_pred, iris.testLabels)
# Specify column names for `merge`
names(merge) <- c("Predicted Species", "Observed Species")
# Inspect `merge`
merge
install.packages("package name")
install.packages("gmodels")
library(gmodels)
CrossTable(x = iris.testLabels, y = iris_pred, prop.chisq=FALSE)
# Create index to split based on labels
index <- createDataPartition(iris$Species, p=0.75, list=FALSE)
install.packages("caret")
library(caret)
# Create index to split based on labels
index <- createDataPartition(iris$Species, p=0.75, list=FALSE)
# Subset training set with index
iris.training <- iris[index,]
# Subset test set with index
iris.test <- iris[-index,]
# Overview of algos supported by caret
names(getModelInfo())
# Train a model
model_knn <- train(iris.training[, 1:4], iris.training[, 5], method='knn')
model_knn
# Predict the labels of the test set
predictions<-predict.train(object=model_knn,iris.test[,1:4], type="raw")
# Evaluate the predictions
table(predictions)
# Confusion matrix
confusionMatrix(predictions,iris.test[,5])
# Train the model with preprocessing
model_knn <- train(iris.training[, 1:4], iris.training[, 5], method='knn', preProcess=c("center", "scale"))
# Predict values
predictions<-predict.train(object=model_knn,iris.test[,1:4], type="raw")
# Confusion matrix
confusionMatrix(predictions,iris.test[,5])
# set working directory - the same where we unpacked the downloaded files
setwd("/Users/Valkoiset/Desktop/SGH/2 semester/Spatial Econometrics/1 lesson")
# clear the workspace, plots and console
rm(list = ls())
if(!is.null(dev.list())) dev.off()
cat("\014")
# packages for i.a. working with maps and visualising data on maps
library(sf)
library(sp)
library(spdep)
library(rgdal)
# packages for i.a. working with maps and visualising data on maps
library(sf)
library(sp)
library(spdep)
library(rgdal)
# import map 1 - level of poviats, correct projection (source: Centralny O?rodek Dokumentacji Geodezyjnej i Kartograficznej,
#                                                       http://www.codgik.gov.pl/index.php/darmowe-dane/prg.html)
mapa1 <- readOGR(".", "powiaty")
#This map is accurate and well-described, but the coordinates are coded in a different way than we need.
#We should recalculate them into degrees of longitude and latitude.
mapa1 <- spTransform(mapa1, "+proj=longlat")
plot(mapa1)
#import map 2 - many levels and countries at a time
#http://ec.europa.eu/eurostat/web/gisco/geodata/reference-data/administrative-units-statistical-units/nuts#nuts13
mapa2 <- readOGR(".", "NUTS_RG_01M_2013")
mapa2 <- spTransform(mapa2, "+proj=longlat")
plot(mapa2)
